{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw observation data\n",
    "\n",
    "Our raw data is from camera traps, each observation has a set of UTM coordinates as well as the species name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Survey Name    Common              Species  \\\n",
      "0  Elephants camera trapping project  Athérure  Atherurus africanus   \n",
      "1  Elephants camera trapping project  Athérure  Atherurus africanus   \n",
      "2  Elephants camera trapping project  Athérure  Atherurus africanus   \n",
      "3  Elephants camera trapping project  Athérure  Atherurus africanus   \n",
      "4  Elephants camera trapping project  Athérure  Atherurus africanus   \n",
      "\n",
      "        Date      Time DayNight         X          Y  Elevation Habitat  ...  \\\n",
      "0  30-Aug-17  03:42:18    Night  507945.5  120331.10      366.0  Forest  ...   \n",
      "1  23-Sep-17  23:37:24    Night  487829.4   21227.15        NaN  Forest  ...   \n",
      "2  20-Dec-17  19:41:44    Night  487829.4   21227.15        NaN  Forest  ...   \n",
      "3  23-Dec-17  20:41:40    Night  487829.4   21227.15        NaN  Forest  ...   \n",
      "4  14-Jun-17  22:56:12    Night  533717.5   85685.04      534.8  Forest  ...   \n",
      "\n",
      "   Group2      Sex Individuals  StationID   CamNumber1   CamNumber2  \\\n",
      "0     NaN      NaN         1.0         52  AMBERE 02_A  AMBERE 02_B   \n",
      "1     NaN  unknown         1.0         76   DZEBE 03_A   DZEBE 03_B   \n",
      "2     NaN  unknown         1.0         76   DZEBE 03_A   DZEBE 03_B   \n",
      "3     NaN  unknown         1.0         76   DZEBE 03_A   DZEBE 03_B   \n",
      "4     NaN  unknown         1.0         44     RN2 01_A     RN2 01_B   \n",
      "\n",
      "                            Image1 Image2 Independent Site  \n",
      "0  AMBERE 02_A_20170830_034218.jpg    NaN        True  NaN  \n",
      "1   DZ_B_ 03_A_20170923_233724.jpg    NaN        True  NaN  \n",
      "2   DZEBE 03_A_20171220_194144.jpg    NaN        True  NaN  \n",
      "3   DZEBE 03_A_20171223_204140.jpg    NaN        True  NaN  \n",
      "4     RN2 01_A_20170630_135255.avi    NaN        True  NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_706/2275657478.py:11: DtypeWarning: Columns (18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, encoding=result['encoding'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "filepath = \"../data/raw_cameratrap.csv\"\n",
    "\n",
    "# Detect the encoding of the file\n",
    "with open(filepath, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame using the detected encoding\n",
    "df = pd.read_csv(filepath, encoding=result['encoding'])\n",
    "\n",
    "# Preview the first 5 rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we transform the UTM coordinates to WGS84 lat, lon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns of interest\n",
    "col_list = ['Common', 'Species', 'Date', 'X', 'Y']\n",
    "df_subset = df[col_list]\n",
    "\n",
    "df_subset['Date'] = pd.to_datetime(df_subset['Date'])\n",
    "df_subset['Year'] = df_subset['Date'].dt.year\n",
    "\n",
    "# Transform UTM to lat, lon\n",
    "import pyproj\n",
    "\n",
    "# Define the UTM zone and hemisphere (N/S)\n",
    "utm_zone = 33\n",
    "utm_hemisphere = 'N'\n",
    "\n",
    "# Create a pyproj Transformer object for the UTM projection\n",
    "utm_crs = pyproj.CRS.from_proj4(f'+proj=utm +zone={utm_zone} +{utm_hemisphere} +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n",
    "\n",
    "# Create a pyproj Transformer object for the WGS 84 Latitude-Longitude projection\n",
    "lat_lon_crs = pyproj.CRS.from_proj4('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')\n",
    "\n",
    "# Create a Transformer object to convert from UTM to Latitude-Longitude\n",
    "transformer = pyproj.Transformer.from_crs(utm_crs, lat_lon_crs)\n",
    "\n",
    "def convert_coordinates(row):\n",
    "    lat, lon = transformer.transform(row['X'], row['Y'])\n",
    "    return pd.Series({'Latitude': lat, 'Longitude': lon})\n",
    "\n",
    "# Apply the function to all rows in the dataframe\n",
    "df_subset[['Latitude', 'Longitude']] = df_subset.apply(convert_coordinates, axis=1)\n",
    "print(df.head())\n",
    "\n",
    "# Summarise the Species column\n",
    "# value_counts = df_subset.groupby(['Common', 'Year']).size().reset_index(name='counts')\n",
    "# value_counts = value_counts.pivot_table(values=\"counts\", index=\"Common\", columns=\"Year\")\n",
    "\n",
    "# print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_706/3154978916.py:11: DtypeWarning: Columns (15,19,30,32,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dung = pd.read_csv(filepath, encoding=result['encoding'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "filepath = \"../data/raw_dung.csv\"\n",
    "\n",
    "# Detect the encoding of the file\n",
    "with open(filepath, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame using the detected encoding\n",
    "df_dung = pd.read_csv(filepath, encoding=result['encoding'])\n",
    "\n",
    "# Select columns of interest\n",
    "col_list = ['Espèces', 'year', 'X', 'Y']\n",
    "df_dung = df_dung[col_list]\n",
    "df_dung = df_dung.rename(columns={'Espèces': 'Species', 'year': 'Year', 'X': 'Latitude', 'Y': 'Longitude'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Convert to geopandas\n",
    "ll_crs = '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'\n",
    "df_dung.crs = ll_crs\n",
    "\n",
    "# Create a geometry column from the latitude and longitude values\n",
    "df_dung['geometry'] = df_dung.apply(lambda x: Point(x.Latitude, x.Longitude), axis=1)\n",
    "\n",
    "# Transform the pandas DataFrame to a GeoPandas DataFrame\n",
    "gdf_dung = gpd.GeoDataFrame(df_dung, geometry='geometry')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip points to area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join cameratrap and gdung df\n",
    "\n",
    "# Convert cameratrap to geopandas df\n",
    "df_subset = df_subset[['Species', 'Year', 'Latitude', 'Longitude']]\n",
    "\n",
    "df_subset['geometry'] = df_subset.apply(lambda x: Point(x.Latitude, x.Longitude), axis=1)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df_subset, geometry='geometry')\n",
    "\n",
    "combined_gdf = pd.concat([gdf, gdf_dung])\n",
    "\n",
    "# Clean data\n",
    "combined_gdf.loc[combined_gdf['Species']==\"Loxodonta africana (éléphant Africain, éléphant d'Afrique) E\", 'Species'] = 'Loxodonta cyclotis'\n",
    "combined_gdf.loc[combined_gdf['Species']==\"Loxodonta africana (Eléphant Africain, Eléphant d'Afrique) E\", 'Species'] = 'Loxodonta cyclotis'\n",
    "combined_gdf.loc[combined_gdf['Species']==\"Loxodonta\", 'Species'] = 'Loxodonta cyclotis'\n",
    "combined_gdf.loc[combined_gdf['Species']==\"Panthera pardus (Léopard, Panthère) PP\", 'Species'] = 'Panthera pardus'\n",
    "combined_gdf.loc[combined_gdf['Species']==\"Pan troglodytes ssp. troglodytes (Chimpanzé) PT\", 'Species'] = 'Pan troglodytes'\n",
    "combined_gdf.loc[combined_gdf['Species']==\"Gorilla gorilla ssp. gorilla (Gorille) GG\", 'Species'] = 'Gorilla gorilla gorilla'\n",
    "\n",
    "combined_gdf.crs = '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Species  Year   Latitude  Longitude                  geometry\n",
      "81197  Panthera pardus  2021  15.069695   1.086870  POINT (15.06969 1.08687)\n",
      "81235  Panthera pardus  2021  15.097350   1.149309  POINT (15.09735 1.14931)\n",
      "81236  Panthera pardus  2021  15.097350   1.149309  POINT (15.09735 1.14931)\n",
      "81237  Panthera pardus  2021  15.097350   1.149309  POINT (15.09735 1.14931)\n",
      "81257  Panthera pardus  2021  15.175696   0.905955  POINT (15.17570 0.90595)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import Point\n",
    "\n",
    "\n",
    "# Create a function to to subset the data by species and year\n",
    "def subset_species(df, species, year):\n",
    "\n",
    "    # Filter by species\n",
    "    try:\n",
    "        df_species = df[(df['Species'] == species) & (df['Year'] == year)]\n",
    "\n",
    "        # Import shapefile of park\n",
    "        park = gpd.read_file('../data/odzala.geojson')\n",
    "        park = park.to_crs(df_species.crs)\n",
    "\n",
    "        # Clip points to park\n",
    "        gdf = df_species[df_species.geometry.intersects(park.geometry.iloc[0])]\n",
    "    \n",
    "    except:\n",
    "        gdf = gpd.GeoDataFrame()\n",
    "\n",
    "    return gdf\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a buffer around points\n",
    "Here we create a 10km2 buffer around points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_buffer(gdf, dist_km):\n",
    "\n",
    "    # Store the current crs\n",
    "    ll_crs = gdf.crs\n",
    "\n",
    "    # Reproject to projected to Africa Sinusoidal projection for accurate distance calculations\n",
    "    as_proj = '+proj=sinu +lon_0=15 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs'\n",
    "    as_gdf = gdf.to_crs(as_proj)\n",
    "\n",
    "    # Create a buffer around each point\n",
    "    buffer_gdf = as_gdf\n",
    "    buffer_gdf['geometry'] = as_gdf.buffer(dist_km*1000)\n",
    "\n",
    "    # Reproject back to lat, lon\n",
    "    ll_gdf = buffer_gdf.to_crs(ll_crs)\n",
    "\n",
    "    return ll_gdf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio import Affine\n",
    "\n",
    "# Input raster and resample to 1000m (0.01)\n",
    "\n",
    "def resample_raster(input_raster, res, output_name):\n",
    "\n",
    "    xres, yres = res, res\n",
    "\n",
    "    with rasterio.open(input_raster) as dataset:\n",
    "        scale_factor_x = dataset.res[0]/xres\n",
    "        scale_factor_y = dataset.res[1]/yres\n",
    "\n",
    "        profile = dataset.profile.copy()\n",
    "        # resample data to target shape\n",
    "        data = dataset.read(\n",
    "            out_shape=(\n",
    "                dataset.count,\n",
    "                int(dataset.height * scale_factor_y),\n",
    "                int(dataset.width * scale_factor_x)\n",
    "            ),\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "\n",
    "        # scale image transform\n",
    "        transform = dataset.transform * dataset.transform.scale(\n",
    "            (1 / scale_factor_x),\n",
    "            (1 / scale_factor_y)\n",
    "        )\n",
    "        profile.update({\"height\": data.shape[-2],\n",
    "                        \"width\": data.shape[-1],\n",
    "                    \"transform\": transform})\n",
    "\n",
    "    with rasterio.open(output_name, \"w\", **profile) as dataset:\n",
    "        dataset.write(data)\n",
    "\n",
    "\n",
    "# resample_raster(\"../data/odzala/odzala_humanfootprint_18.tif\", 0.01, \"../data/odzala/output18.tif\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with rasterio.open('../data/odzala/output.tif') as src:\n",
    "#     image = src.read(1)\n",
    "#     plt.imshow(image, cmap='gray')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform polygons to raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.features import geometry_mask\n",
    "\n",
    "def poly_to_raster(gdf, input_raster, output_name):\n",
    "    with rasterio.open(input_raster) as src:\n",
    "        image = src.read(1)\n",
    "\n",
    "    mask = geometry_mask(gdf[\"geometry\"], transform=src.transform, out_shape=src.shape)\n",
    "    image[~mask] = 1\n",
    "    image[mask] = 0\n",
    "\n",
    "    meta = src.meta.copy()\n",
    "    meta.update(compress='lzw')\n",
    "\n",
    "    # Save the raster to a TIFF file\n",
    "    with rasterio.open(output_name, \"w\", **meta) as dst:\n",
    "        dst.write(image, 1)\n",
    "\n",
    "\n",
    "# poly_to_raster(test2, '../data/odzala/output18.tif', \"../data/odzala/leopard.tif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the resample_raster function to upsample the human-footprint\n",
    "Here, we read the 30m human-footprint rasters and then apply the `resample_raster` function to upsample each raster to 1000m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample all 30m human_footprint rasters to 1000m\n",
    "\n",
    "# List all files\n",
    "import os\n",
    "directory = '../data/odzala/human_footprint_30/'\n",
    "\n",
    "# Get a list of all files in the directory and their full paths\n",
    "files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "for file_path in files:\n",
    "\n",
    "    # Get just the filename from the file path and remove extension\n",
    "    filename = os.path.basename(file_path)\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Resample raster and write to different folder\n",
    "    resample_raster(file_path, 0.01, \"../data/odzala/human_footprint_1000/\" + filename + \"_1000.tif\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create rasters from species polygons\n",
    "Here, we apply the `subset_species`, `create_buffer` and `poly_to_raster` functions to process the observation data into rasters. Each raster is specific to a species and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rasters of species data\n",
    "import os\n",
    "\n",
    "key_species = ['Loxodonta cyclotis', 'Panthera pardus', 'Pan troglodytes', 'Gorilla gorilla gorilla', 'Hylochoerus meinertzhageni']\n",
    "years = [2017, 2018, 2019, 2020, 2021]\n",
    "\n",
    "\n",
    "for species in key_species:\n",
    "    for year in years:\n",
    "        df_species = subset_species(df_subset, species, year)\n",
    "\n",
    "        if not df_species.empty:\n",
    "            df_buffer = create_buffer(df_species, 10)\n",
    "\n",
    "            output_folder_path = '../data/odzala/species/' + str(year)\n",
    "\n",
    "            if not os.path.exists(output_folder_path):\n",
    "                os.makedirs(output_folder_path)\n",
    "            \n",
    "            poly_to_raster(df_buffer, '../data/odzala/human_footprint_1000/odzala_humanfootprint_17_1000.tif', output_folder_path + '/' + str(year) + '_' + species + '.tif')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now combine the species rasters into one biodiversity raster\n",
    "\n",
    "We want to know how many of the key species were observed in a given year. As such, we sum the values for each species raster and create an aggregate raster for the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# List all rasters in the folder\n",
    "years = [2017, 2018, 2019, 2020, 2021]\n",
    "\n",
    "\n",
    "def sum_rasters(year):\n",
    "    folder = '../data/odzala/species/' + str(year)\n",
    "    rasters = [f for f in os.listdir(folder) if f.endswith(\".tif\")]\n",
    "\n",
    "    # Read the first raster and get its shape and CRS\n",
    "    with rasterio.open(os.path.join(folder, rasters[0])) as src:\n",
    "        shape = src.shape\n",
    "        crs = src.crs\n",
    "        first_raster = src.read(1)\n",
    "\n",
    "    # Initialize the sum with the first raster\n",
    "    result = first_raster.astype(float)\n",
    "\n",
    "    # Loop through the remaining rasters and add them to the sum\n",
    "    for raster in rasters[1:]:\n",
    "        with rasterio.open(os.path.join(folder, raster)) as src:\n",
    "            result += src.read(1).astype(float)\n",
    "\n",
    "    # Write the sum to a new raster\n",
    "    filename = '../data/odzala/species/Summed/'+ str(year) + '.tif'\n",
    "    with rasterio.open(filename, 'w', driver='GTiff', height=shape[0],\n",
    "                    width=shape[1], count=1, dtype=np.float32,\n",
    "                    crs=crs, transform=src.transform) as dst:\n",
    "          dst.write(result.astype(np.float32), 1)\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    sum_rasters(year)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create maps\n",
    "First, we create maps of the human-footprint mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder = '../data/odzala/human_footprint_1000/'\n",
    "rasters = sorted([f for f in os.listdir(folder) if f.endswith(\".tif\")])\n",
    "\n",
    "# Read shapefile of park\n",
    "park = gpd.read_file('../data/odzala.geojson')\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "cmap = plt.get_cmap(\"Reds\")\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    with rasterio.open(os.path.join(folder, rasters[i])) as src:\n",
    "        title = '20' + rasters[i].split(\"_\")[2]\n",
    "        image = src.read(1)\n",
    "        image = np.ma.masked_where(image < 0.002, image) # 0.002 indicates more than two 30m pixels to be deforested within the 1000m pixel.\n",
    "\n",
    "        # Transform values to exponential if of interest\n",
    "        # image = np.exp(image)\n",
    "\n",
    "        extent = src.bounds\n",
    "\n",
    "        park = park.to_crs(src.crs)\n",
    "\n",
    "        ax.imshow(image, extent=(extent.left, extent.right, extent.bottom, extent.top), origin='upper', cmap='Reds')\n",
    "        park.boundary.plot(ax=ax, color='green', linewidth=0.5)\n",
    "        ax.set_title(title, fontsize=20)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "# cbar = fig.colorbar(axes[4].imshow(image, cmap=cmap), ax=axes, orientation=\"horizontal\", fraction=0.046, pad=1, anchor=(0.5, -0.1))\n",
    "# cbar.ax.tick_params(labelsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('../data/odzala/plots/humanfootprint_linear.png', bbox_inches='tight', dpi=300)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create maps for the species observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder = '../data/odzala/species/Summed/'\n",
    "rasters = sorted([f for f in os.listdir(folder) if f.endswith(\".tif\")])\n",
    "\n",
    "# Read shapefile of park\n",
    "park = gpd.read_file('../data/odzala.geojson')\n",
    "\n",
    "cmap = plt.get_cmap(\"Greens\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    with rasterio.open(os.path.join(folder, rasters[i])) as src:\n",
    "        title = rasters[i].split(\".\")[0]\n",
    "        image = src.read(1)\n",
    "        image = np.ma.masked_where(image == 0, image) \n",
    "\n",
    "        extent = src.bounds\n",
    "\n",
    "        park = park.to_crs(src.crs)\n",
    "\n",
    "        ax.imshow(image, extent=(extent.left, extent.right, extent.bottom, extent.top), origin='upper', cmap='Greens')\n",
    "        park.boundary.plot(ax=ax, color='green', linewidth=0.5)\n",
    "        ax.set_title(title, fontsize=20)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "# cbar = fig.colorbar(axes[4].imshow(image, cmap=cmap), ax=axes, orientation=\"horizontal\", fraction=0.046, pad=1, anchor=(0.5, -0.1), ticks=[1, 2, 3, 4, 5])\n",
    "# cbar.ax.tick_params(labelsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('../data/odzala/plots/species.png', bbox_inches='tight', dpi=300)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarise rasters within polgyon\n",
    "Here, we attempt to count the number of pixels in each raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterstats import zonal_stats\n",
    "\n",
    "\n",
    "def summarise_raster(raster_path, year):\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster = src.read(1)\n",
    "        affine=src.transform\n",
    "\n",
    "        # Read the polygon\n",
    "        park = gpd.read_file('../data/odzala.geojson')\n",
    "\n",
    "        # Calculate zonal statistics\n",
    "        stats = zonal_stats(park, raster, affine=affine)[0]\n",
    "\n",
    "        # Add the year into the dict\n",
    "        stats['year'] = int(year)\n",
    "\n",
    "        return stats\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe of all results by looping through the human-footprint images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../data/odzala/human_footprint_1000/'\n",
    "rasters = sorted([f for f in os.listdir(folder) if f.endswith(\".tif\")])\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for raster in rasters:\n",
    "    raster_path = folder+raster\n",
    "    raster_year = '20' + raster_path.split(\"_\")[4]\n",
    "\n",
    "    results = summarise_raster(raster_path, raster_year)\n",
    "    results_list.append(results)\n",
    "\n",
    "# Create a dataframe\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Save a csv file\n",
    "results_df.to_csv(\"../data/odzala/results/human_footprint.csv\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, also for the species rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../data/odzala/species/Summed/'\n",
    "rasters = sorted([f for f in os.listdir(folder) if f.endswith(\".tif\")])\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for raster in rasters:\n",
    "    raster_path = folder+raster\n",
    "    raster_year = raster.split(\".\")[0]\n",
    "\n",
    "    results = summarise_raster(raster_path, raster_year)\n",
    "    results_list.append(results)\n",
    "\n",
    "# Create a dataframe\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Save a csv file\n",
    "results_df.to_csv(\"../data/odzala/results/species.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export rasters as CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# Open the raster file using rasterio\n",
    "with rasterio.open(\"../data/odzala/human_footprint_1000/odzala_humanfootprint_17_1000.tif\") as src:\n",
    "    # Read the data from the raster into a numpy array\n",
    "    data = src.read(1)\n",
    "    # Convert the data to a flattened 1D array\n",
    "    flat_data = data.flatten()\n",
    "    # Write the data to a CSV file\n",
    "    np.savetxt(\"../data/odzala/results/odzala_humanfootprint_17_1000.csv\", data, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "714ad8e22d5d8b3d120ee3023df86cba0833167059211873a053cee17d54cbe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
