{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw observation data\n",
    "\n",
    "Our raw data is a set of csv files as following:\n",
    "- Camera trap observations: each observation has a set of UTM coordinates as well as the species name\n",
    "- Dung count for 2022\n",
    "- Dung count for 2019\n",
    "\n",
    "### Import camera trap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "filepath = \"../data/raw_cameratrap.csv\"\n",
    "\n",
    "# Detect the encoding of the file\n",
    "with open(filepath, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame using the detected encoding\n",
    "df = pd.read_csv(filepath, encoding=result['encoding'])\n",
    "\n",
    "# Preview the first 5 rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we transform the UTM coordinates to WGS84 lat, lon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns of interest\n",
    "col_list = ['Common', 'Species', 'Date', 'X', 'Y']\n",
    "df_subset = df[col_list]\n",
    "\n",
    "df_subset['Date'] = pd.to_datetime(df_subset['Date'])\n",
    "df_subset['Year'] = df_subset['Date'].dt.year\n",
    "\n",
    "# Transform UTM to lat, lon\n",
    "import pyproj\n",
    "\n",
    "# Define the UTM zone and hemisphere (N/S)\n",
    "utm_zone = 33\n",
    "utm_hemisphere = 'N'\n",
    "\n",
    "# Create a pyproj Transformer object for the UTM projection\n",
    "utm_crs = pyproj.CRS.from_proj4(f'+proj=utm +zone={utm_zone} +{utm_hemisphere} +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n",
    "\n",
    "# Create a pyproj Transformer object for the WGS 84 Latitude-Longitude projection\n",
    "lat_lon_crs = pyproj.CRS.from_proj4('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')\n",
    "\n",
    "# Create a Transformer object to convert from UTM to Latitude-Longitude\n",
    "transformer = pyproj.Transformer.from_crs(utm_crs, lat_lon_crs)\n",
    "\n",
    "def convert_coordinates(row):\n",
    "    lat, lon = transformer.transform(row['X'], row['Y'])\n",
    "    return pd.Series({'Latitude': lat, 'Longitude': lon})\n",
    "\n",
    "# Apply the function to all rows in the dataframe\n",
    "df_subset[['Latitude', 'Longitude']] = df_subset.apply(convert_coordinates, axis=1)\n",
    "print(df.head())\n",
    "\n",
    "# Summarise the Species column\n",
    "# value_counts = df_subset.groupby(['Common', 'Year']).size().reset_index(name='counts')\n",
    "# value_counts = value_counts.pivot_table(values=\"counts\", index=\"Common\", columns=\"Year\")\n",
    "\n",
    "# print(value_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dung data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "# Select columns of interest\n",
    "col_list = ['Espèces', 'year', 'X', 'Y']\n",
    "\n",
    "# Dung count for 2022\n",
    "filepath_22 = \"../data/raw_dung.csv\"\n",
    "\n",
    "# Detect the encoding of the file\n",
    "with open(filepath_22, 'rb') as f:\n",
    "    result_22 = chardet.detect(f.read())\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame using the detected encoding\n",
    "df_dung_22 = pd.read_csv(filepath_22, encoding=result['encoding'])\n",
    "df_dung_22 = df_dung_22[col_list]\n",
    "\n",
    "# Dung count for 2019\n",
    "\n",
    "filepath_19 = \"../data/raw_dung2019.csv\"\n",
    "\n",
    "# Detect the encoding of the file\n",
    "with open(filepath_19, 'rb') as f:\n",
    "    result_22 = chardet.detect(f.read())\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame using the detected encoding\n",
    "df_dung_19 = pd.read_csv(filepath_19, encoding=result['encoding'])\n",
    "df_dung_19 = df_dung_19[col_list]\n",
    "\n",
    "\n",
    "# Concatenate two datasets\n",
    "df_dung = df_dung_22.append(df_dung_19)\n",
    "\n",
    "df_dung = df_dung.rename(columns={'Espèces': 'Species', 'year': 'Year', 'X': 'Latitude', 'Y': 'Longitude'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Convert to geopandas\n",
    "ll_crs = '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'\n",
    "df_dung.crs = ll_crs\n",
    "\n",
    "# Create a geometry column from the latitude and longitude values\n",
    "df_dung['geometry'] = df_dung.apply(lambda x: Point(x.Latitude, x.Longitude), axis=1)\n",
    "\n",
    "# Transform the pandas DataFrame to a GeoPandas DataFrame\n",
    "gdf_dung = gpd.GeoDataFrame(df_dung, geometry='geometry')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip points to area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "gdf_dung.loc[gdf_dung['Species']==\"Loxodonta africana (éléphant Africain, éléphant d'Afrique) E\", 'Species'] = 'Loxodonta cyclotis'\n",
    "gdf_dung.loc[gdf_dung['Species']==\"Loxodonta africana (Eléphant Africain, Eléphant d'Afrique) E\", 'Species'] = 'Loxodonta cyclotis'\n",
    "gdf_dung.loc[gdf_dung['Species']==\"Loxodonta africana (Ã‰lÃ©phant Africain, Ã‰lÃ©phant d'Afrique) E\", 'Species'] = 'Loxodonta cyclotis'\n",
    "gdf_dung.loc[gdf_dung['Species']==\"Loxodonta\", 'Species'] = 'Loxodonta cyclotis'\n",
    "gdf_dung.loc[gdf_dung['Species']==\"Panthera pardus (Léopard, Panthère) PP\", 'Species'] = 'Panthera pardus'\n",
    "gdf_dung.loc[gdf_dung['Species']==\"Panthera pardus (LÃ©opard, PanthÃ¨re) PP\", 'Species'] = 'Panthera pardus'\n",
    "gdf_dung.loc[gdf_dung['Species']==\"Pan troglodytes ssp. troglodytes (Chimpanzé) PT\", 'Species'] = 'Pan troglodytes'\n",
    "gdf_dung.loc[gdf_dung['Species']==\"Pan troglodytes ssp. troglodytes (ChimpanzÃ©) PT\", 'Species'] = 'Pan troglodytes'\n",
    "gdf_dung.loc[gdf_dung['Species']==\"Gorilla gorilla ssp. gorilla (Gorille) GG\", 'Species'] = 'Gorilla gorilla gorilla'\n",
    "\n",
    "# print(gdf_dung.sort_values('Species').value_counts('Species').sort_index(ascending=True))\n",
    "\n",
    "\n",
    "gdf_dung.crs = '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'\n",
    "\n",
    "# Join cameratrap and gdung df\n",
    "\n",
    "# Convert cameratrap to geopandas df\n",
    "df_subset = df_subset[['Species', 'Year', 'Latitude', 'Longitude']]\n",
    "\n",
    "df_subset['geometry'] = df_subset.apply(lambda x: Point(x.Latitude, x.Longitude), axis=1)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df_subset, geometry='geometry')\n",
    "\n",
    "combined_gdf = pd.concat([gdf, gdf_dung])\n",
    "\n",
    "\n",
    "\n",
    "# combined_gdf.crs = '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely import Point\n",
    "\n",
    "\n",
    "# Create a function to to subset the data by species and year\n",
    "def subset_species(input_df, species, year):\n",
    "\n",
    "    # Filter by species\n",
    "    try:\n",
    "        df_species = input_df[(input_df['Species'] == species) & (input_df['Year'] == year)]\n",
    "\n",
    "        # Import shapefile of park\n",
    "        park = gpd.read_file('../data/odzala.geojson')\n",
    "        park = park.to_crs(df_species.crs)\n",
    "        park_buffer = park\n",
    "        park_buffer['geometry'] = park.buffer(50*1000)\n",
    "\n",
    "        # Clip points to park\n",
    "        gdf = df_species[df_species.geometry.intersects(park_buffer.geometry.iloc[0])]\n",
    "    \n",
    "    except:\n",
    "        gdf = gpd.GeoDataFrame()\n",
    "\n",
    "    return gdf\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a buffer around points\n",
    "Here we create a 10km2 buffer around points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_buffer(gdf, dist_km):\n",
    "\n",
    "    # Store the current crs\n",
    "    ll_crs = gdf.crs\n",
    "\n",
    "    # Reproject to projected to Africa Sinusoidal projection for accurate distance calculations\n",
    "    as_proj = '+proj=sinu +lon_0=15 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +type=crs'\n",
    "    as_gdf = gdf.to_crs(as_proj)\n",
    "\n",
    "    # Create a buffer around each point\n",
    "    buffer_gdf = as_gdf\n",
    "    buffer_gdf['geometry'] = as_gdf.buffer(dist_km*1000)\n",
    "\n",
    "    # Reproject back to lat, lon\n",
    "    ll_gdf = buffer_gdf.to_crs(ll_crs)\n",
    "\n",
    "    return ll_gdf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio import Affine\n",
    "\n",
    "# Input raster and resample to 1000m (0.01)\n",
    "\n",
    "def resample_raster(input_raster, res, output_name):\n",
    "\n",
    "    xres, yres = res, res\n",
    "\n",
    "    with rasterio.open(input_raster) as dataset:\n",
    "        scale_factor_x = dataset.res[0]/xres\n",
    "        scale_factor_y = dataset.res[1]/yres\n",
    "\n",
    "        profile = dataset.profile.copy()\n",
    "        # resample data to target shape\n",
    "        data = dataset.read(\n",
    "            out_shape=(\n",
    "                dataset.count,\n",
    "                int(dataset.height * scale_factor_y),\n",
    "                int(dataset.width * scale_factor_x)\n",
    "            ),\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "\n",
    "        # scale image transform\n",
    "        transform = dataset.transform * dataset.transform.scale(\n",
    "            (1 / scale_factor_x),\n",
    "            (1 / scale_factor_y)\n",
    "        )\n",
    "        profile.update({\"height\": data.shape[-2],\n",
    "                        \"width\": data.shape[-1],\n",
    "                    \"transform\": transform})\n",
    "\n",
    "    with rasterio.open(output_name, \"w\", **profile) as dataset:\n",
    "        dataset.write(data)\n",
    "\n",
    "\n",
    "# resample_raster(\"../data/odzala/odzala_humanfootprint_18.tif\", 0.01, \"../data/odzala/output18.tif\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with rasterio.open('../data/odzala/output.tif') as src:\n",
    "#     image = src.read(1)\n",
    "#     plt.imshow(image, cmap='gray')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform polygons to raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.features import geometry_mask\n",
    "\n",
    "def poly_to_raster(gdf, input_raster, output_name):\n",
    "    with rasterio.open(input_raster) as src:\n",
    "        image = src.read(1)\n",
    "\n",
    "    mask = geometry_mask(gdf[\"geometry\"], transform=src.transform, out_shape=src.shape)\n",
    "    image[~mask] = 1\n",
    "    image[mask] = 0\n",
    "\n",
    "    meta = src.meta.copy()\n",
    "    meta.update(compress='lzw')\n",
    "\n",
    "    # Save the raster to a TIFF file\n",
    "    with rasterio.open(output_name, \"w\", **meta) as dst:\n",
    "        dst.write(image, 1)\n",
    "\n",
    "\n",
    "# poly_to_raster(test2, '../data/odzala/output18.tif', \"../data/odzala/leopard.tif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the resample_raster function to upsample the human-footprint\n",
    "Here, we read the 30m human-footprint rasters and then apply the `resample_raster` function to upsample each raster to 1000m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample all 30m human_footprint rasters to 1000m\n",
    "\n",
    "# List all files\n",
    "import os\n",
    "directory = '../data/odzala/human_footprint_30/'\n",
    "\n",
    "# Get a list of all files in the directory and their full paths\n",
    "files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "for file_path in files:\n",
    "\n",
    "    # Get just the filename from the file path and remove extension\n",
    "    filename = os.path.basename(file_path)\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Resample raster and write to different folder\n",
    "    resample_raster(file_path, 0.01, \"../data/odzala/human_footprint_1000/\" + filename + \"_1000.tif\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create rasters from species polygons\n",
    "Here, we apply the `subset_species`, `create_buffer` and `poly_to_raster` functions to process the observation data into rasters. Each raster is specific to a species and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rasters of species data\n",
    "import os\n",
    "\n",
    "key_species = ['Loxodonta cyclotis', 'Panthera pardus', 'Pan troglodytes', 'Gorilla gorilla gorilla', 'Hylochoerus meinertzhageni']\n",
    "years = [2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "\n",
    "\n",
    "for species in key_species:\n",
    "    for year in years:\n",
    "        df_species = subset_species(combined_gdf, species, year)\n",
    "        # df_species.to_file(\"../data/odzala/results/\" + species + str(year) + '.geojson', driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "        if not df_species.empty:\n",
    "            df_buffer = create_buffer(df_species, 10)\n",
    "\n",
    "            output_folder_path = '../data/odzala/species2/' + str(year)\n",
    "\n",
    "            if not os.path.exists(output_folder_path):\n",
    "                os.makedirs(output_folder_path)\n",
    "            \n",
    "            poly_to_raster(df_buffer, '../data/odzala/human_footprint_1000/odzala_humanfootprint_17_1000.tif', output_folder_path + '/' + str(year) + '_' + species + '.tif')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now combine the species rasters into one biodiversity raster\n",
    "\n",
    "We want to know how many of the key species were observed in a given year. As such, we sum the values for each species raster and create an aggregate raster for the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# List all rasters in the folder\n",
    "years = [2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "\n",
    "def sum_rasters(year):\n",
    "    folder = '../data/odzala/species2/' + str(year)\n",
    "    rasters = [f for f in os.listdir(folder) if f.endswith(\".tif\")]\n",
    "\n",
    "    # Read the first raster and get its shape and CRS\n",
    "    with rasterio.open(os.path.join(folder, rasters[0])) as src:\n",
    "        shape = src.shape\n",
    "        crs = src.crs\n",
    "        first_raster = src.read(1)\n",
    "\n",
    "    # Initialize the sum with the first raster\n",
    "    result = first_raster.astype(float)\n",
    "\n",
    "    # Loop through the remaining rasters and add them to the sum\n",
    "    for raster in rasters[1:]:\n",
    "        with rasterio.open(os.path.join(folder, raster)) as src:\n",
    "            result += src.read(1).astype(float)\n",
    "\n",
    "    # Write the sum to a new raster\n",
    "    filename = '../data/odzala/species2/Summed/'+ str(year) + '.tif'\n",
    "    with rasterio.open(filename, 'w', driver='GTiff', height=shape[0],\n",
    "                    width=shape[1], count=1, dtype=np.float32,\n",
    "                    crs=crs, transform=src.transform) as dst:\n",
    "          dst.write(result.astype(np.float32), 1)\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    sum_rasters(year)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create maps\n",
    "First, we create maps of the human-footprint mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder = '../data/odzala/human_footprint_1000/'\n",
    "rasters = sorted([f for f in os.listdir(folder) if f.endswith(\".tif\")])\n",
    "\n",
    "# Read shapefile of park\n",
    "park = gpd.read_file('../data/odzala.geojson')\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "cmap = plt.get_cmap(\"Reds\")\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    with rasterio.open(os.path.join(folder, rasters[i])) as src:\n",
    "        title = '20' + rasters[i].split(\"_\")[2]\n",
    "        image = src.read(1)\n",
    "        image = np.ma.masked_where(image < 0.002, image) # 0.002 indicates more than two 30m pixels to be deforested within the 1000m pixel.\n",
    "\n",
    "        # Transform values to exponential if of interest\n",
    "        # image = np.exp(image)\n",
    "\n",
    "        extent = src.bounds\n",
    "\n",
    "        park = park.to_crs(src.crs)\n",
    "\n",
    "        ax.imshow(image, extent=(extent.left, extent.right, extent.bottom, extent.top), origin='upper', cmap='Reds')\n",
    "        park.boundary.plot(ax=ax, color='green', linewidth=0.5)\n",
    "        ax.set_title(title, fontsize=20)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "# cbar = fig.colorbar(axes[4].imshow(image, cmap=cmap), ax=axes, orientation=\"horizontal\", fraction=0.046, pad=1, anchor=(0.5, -0.1))\n",
    "# cbar.ax.tick_params(labelsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('../data/odzala/plots/humanfootprint_linear.png', bbox_inches='tight', dpi=300)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create maps for the species observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "folder = '../data/odzala/species2/Summed/'\n",
    "rasters = sorted([f for f in os.listdir(folder) if f.endswith(\".tif\")])\n",
    "\n",
    "# Read shapefile of park\n",
    "park = gpd.read_file('../data/odzala.geojson')\n",
    "\n",
    "# cmap = plt.get_cmap(\"Greens\")\n",
    "cmap = colors.ListedColormap(['#addd8e', '#78c679', '#31a354', '#006837', '#003e21'])\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 6, figsize=(20, 5))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    with rasterio.open(os.path.join(folder, rasters[i])) as src:\n",
    "        title = rasters[i].split(\".\")[0]\n",
    "        image = src.read(1)\n",
    "        image = np.ma.masked_where(image == 0, image) \n",
    "\n",
    "        extent = src.bounds\n",
    "\n",
    "        park = park.to_crs(src.crs)\n",
    "\n",
    "        ax.imshow(image, extent=(extent.left, extent.right, extent.bottom, extent.top), origin='upper', cmap=cmap)\n",
    "        park.boundary.plot(ax=ax, color='green', linewidth=0.5)\n",
    "        ax.set_title(title, fontsize=20)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "# cbar = fig.colorbar(axes[4].imshow(image, cmap=cmap), ax=axes, orientation=\"horizontal\", fraction=0.046, pad=1, anchor=(0.5, -0.1))\n",
    "# cbar.ax.tick_params(labelsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('../data/odzala/plots/species22.png', bbox_inches='tight', dpi=300)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarise rasters within polgyon\n",
    "Here, we attempt to count the number of pixels in each raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterstats import zonal_stats\n",
    "\n",
    "\n",
    "def summarise_raster(raster_path, year):\n",
    "\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster = src.read(1)\n",
    "        affine=src.transform\n",
    "\n",
    "        # Read the polygon\n",
    "        park = gpd.read_file('../data/odzala.geojson')\n",
    "\n",
    "        # Calculate zonal statistics\n",
    "        stats = zonal_stats(park, raster, affine=affine)[0]\n",
    "\n",
    "        # Add the year into the dict\n",
    "        stats['year'] = int(year)\n",
    "\n",
    "        return stats\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe of all results by looping through the human-footprint images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../data/odzala/human_footprint_1000/'\n",
    "rasters = sorted([f for f in os.listdir(folder) if f.endswith(\".tif\")])\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for raster in rasters:\n",
    "    raster_path = folder+raster\n",
    "    raster_year = '20' + raster_path.split(\"_\")[4]\n",
    "\n",
    "    results = summarise_raster(raster_path, raster_year)\n",
    "    results_list.append(results)\n",
    "\n",
    "# Create a dataframe\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Save a csv file\n",
    "results_df.to_csv(\"../data/odzala/results/human_footprint.csv\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, also for the species rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../data/odzala/species2/Summed/'\n",
    "rasters = sorted([f for f in os.listdir(folder) if f.endswith(\".tif\")])\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for raster in rasters:\n",
    "    raster_path = folder+raster\n",
    "    raster_year = raster.split(\".\")[0]\n",
    "\n",
    "    results = summarise_raster(raster_path, raster_year)\n",
    "    results_list.append(results)\n",
    "\n",
    "# Create a dataframe\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Save a csv file\n",
    "results_df.to_csv(\"../data/odzala/results/species22.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export rasters as CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# Open the raster file using rasterio\n",
    "with rasterio.open(\"../data/odzala/human_footprint_1000/odzala_humanfootprint_17_1000.tif\") as src:\n",
    "    # Read the data from the raster into a numpy array\n",
    "    data = src.read(1)\n",
    "    # Convert the data to a flattened 1D array\n",
    "    flat_data = data.flatten()\n",
    "    # Write the data to a CSV file\n",
    "    np.savetxt(\"../data/odzala/results/odzala_humanfootprint_17_1000.csv\", data, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "714ad8e22d5d8b3d120ee3023df86cba0833167059211873a053cee17d54cbe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
